{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>town</th>\n",
       "      <th>mortality</th>\n",
       "      <th>hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South</td>\n",
       "      <td>Bath</td>\n",
       "      <td>1247</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North</td>\n",
       "      <td>Birkenhead</td>\n",
       "      <td>1668</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>1466</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>North</td>\n",
       "      <td>Blackburn</td>\n",
       "      <td>1800</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>North</td>\n",
       "      <td>Blackpool</td>\n",
       "      <td>1609</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location        town  mortality  hardness\n",
       "0    South        Bath       1247       105\n",
       "1    North  Birkenhead       1668        17\n",
       "2    South  Birmingham       1466         5\n",
       "3    North   Blackburn       1800        14\n",
       "4    North   Blackpool       1609        18"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.weightstats import _zconfint_generic, _tconfint_generic\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('water.txt', sep=\"\\t\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(dataframe):\n",
    "    mean = np.mean(dataframe)\n",
    "    mean_std = dataframe.std(ddof=1)/np.sqrt(len(dataframe))\n",
    "    print _tconfint_generic(mean, mean_std,\n",
    "    len(dataframe) - 1,\n",
    "    0.05, 'two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1476.0833413552848, 1572.2117406119285)\n",
      "(1320.1517462936238, 1433.463638321761)\n",
      "(53.467198692036106, 86.07126284642544)\n",
      "(21.42248728572426, 39.37751271427574)\n"
     ]
    }
   ],
   "source": [
    "calculate(data['mortality'])\n",
    "calculate(data[data['location'] == 'South']['mortality'])\n",
    "\n",
    "calculate(data[data['location'] == 'South']['hardness'])\n",
    "calculate(data[data['location'] == 'North']['hardness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import samplesize_confint_proportion\n",
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003539259271646236\n"
     ]
    }
   ],
   "source": [
    "wilson_interval = proportion_confint(1, 50, method = 'wilson')\n",
    "print wilson_interval[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753\n"
     ]
    }
   ],
   "source": [
    "n_samples = int(np.ceil(samplesize_confint_proportion(0.02, 0.01)))\n",
    "print n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.compat.python import lzip, range\n",
    "import numpy as np\n",
    "from scipy import stats, optimize\n",
    "from sys import float_info\n",
    "\n",
    "from statsmodels.stats.base import AllPairsResults\n",
    "from statsmodels.tools.sm_exceptions import HypothesisTestWarning\n",
    "\n",
    "\n",
    "def proportion_confint_custom(count, nobs, alpha=0.05, method='normal'):\n",
    "    pd_index = getattr(count, 'index', None)\n",
    "    if pd_index is not None and hasattr(pd_index, '__call__'):\n",
    "        # this rules out lists, lists have an index method\n",
    "        pd_index = None\n",
    "    count = np.asarray(count)\n",
    "    nobs = np.asarray(nobs)\n",
    "\n",
    "    q_ = count * 1. / nobs\n",
    "    alpha_2 = 0.5 * alpha\n",
    "\n",
    "    if method == 'normal':\n",
    "        std_ = np.sqrt(q_ * (1 - q_) / nobs)\n",
    "        dist = stats.norm.isf(alpha / 2.) * std_\n",
    "        ci_low = q_ - dist\n",
    "        ci_upp = q_ + dist\n",
    "\n",
    "    elif method == 'binom_test':\n",
    "        # inverting the binomial test\n",
    "        def func(qi):\n",
    "            return stats.binom_test(q_ * nobs, nobs, p=qi) - alpha\n",
    "        if count == 0:\n",
    "            ci_low = 0\n",
    "        else:\n",
    "            ci_low = optimize.brentq(func, float_info.min, q_)\n",
    "        if count == nobs:\n",
    "            ci_upp = 1\n",
    "        else:\n",
    "            ci_upp = optimize.brentq(func, q_, 1. - float_info.epsilon)\n",
    "\n",
    "    elif method == 'beta':\n",
    "        ci_low = stats.beta.ppf(alpha_2, count, nobs - count + 1)\n",
    "        ci_upp = stats.beta.isf(alpha_2, count + 1, nobs - count)\n",
    "\n",
    "        if np.ndim(ci_low) > 0:\n",
    "            ci_low[q_ == 0] = 0\n",
    "            ci_upp[q_ == 1] = 1\n",
    "        else:\n",
    "            ci_low = ci_low if (q_ != 0) else 0\n",
    "            ci_upp = ci_upp if (q_ != 1) else 1\n",
    "\n",
    "    elif method == 'agresti_coull':\n",
    "        crit = stats.norm.isf(alpha / 2.)\n",
    "        nobs_c = nobs + crit**2\n",
    "        q_c = (count + crit**2 / 2.) / nobs_c\n",
    "        std_c = np.sqrt(q_c * (1. - q_c) / nobs_c)\n",
    "        dist = crit * std_c\n",
    "        ci_low = q_c - dist\n",
    "        ci_upp = q_c + dist\n",
    "\n",
    "    elif method == 'wilson':\n",
    "        crit = stats.norm.isf(alpha / 2.)\n",
    "        crit2 = crit**2\n",
    "        denom = 1 + crit2 / nobs\n",
    "        center = (q_ + crit2 / (2 * nobs)) / denom\n",
    "        dist = crit * np.sqrt(q_ * (1. - q_) / nobs + crit2 / (4. * nobs**2))\n",
    "        dist /= denom\n",
    "        ci_low = center - dist\n",
    "        ci_upp = center + dist\n",
    "\n",
    "    # method adjusted to be more forgiving of misspellings or incorrect option name\n",
    "    elif method[:4] == 'jeff':\n",
    "        ci_low, ci_upp = stats.beta.interval(1 - alpha, count + 0.5,\n",
    "                                             nobs - count + 0.5)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError('method \"%s\" is not available' % method)\n",
    "\n",
    "    if pd_index is not None and np.ndim(ci_low) > 0:\n",
    "        import pandas as pd\n",
    "        if np.ndim(ci_low) == 1:\n",
    "            ci_low = pd.Series(ci_low, index=pd_index)\n",
    "            ci_upp = pd.Series(ci_upp, index=pd_index)\n",
    "        if np.ndim(ci_low) == 2:\n",
    "            ci_low = pd.DataFrame(ci_low, index=pd_index)\n",
    "            ci_upp = pd.DataFrame(ci_upp, index=pd_index)\n",
    "\n",
    "    return ci_low, ci_upp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.018805307081790987\n"
     ]
    }
   ],
   "source": [
    "normal_interval = proportion_confint_custom(1, 50, method = 'normal')\n",
    "print normal_interval[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Уточнение правила трёх сигм\n",
    "\n",
    "Не забудьте, что при построении интервала остаточную вероятностную массу нужно делить между двумя хвостами распределения (если вы не понимаете, что имеется в виду, попробуйте вернуться к видео \"Интервальные оценки с помощью квантилей\" и обратите внимание, квантили какого порядка используются при построении 95% интервала).\n",
    "Не рекомендуется использовать \"аналоговые\" таблицы квантилей — в них легко могут быть опечатки, числа там могут быть слишком сильно округлены, да и в целом это способ прошлого века."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9677379253417944"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "rv = norm(0,1)\n",
    "rv.ppf(0.9985)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Снижение вероятности инфаркта при приёме аспирина\n",
    "\n",
    "* Имеющиеся у нас выборки бинарны, поэтому работать с ними нужно методами для долей — tconfint не пойдёт.\n",
    "* Проверьте, что вы взяли разность долей в том порядке, в котором этого требует условие задания.\n",
    "* В этом задании часто ошибка возникает из-за невнимательности — проверьте, что вы не перепутали числа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007706023976\n"
     ]
    }
   ],
   "source": [
    "p = 104.0/11037\n",
    "\n",
    "p_1 = 189.0/11034\n",
    "\n",
    "print p_1 - p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Доверительный интервал для снижения вероятности инфаркта при приёме аспирина\n",
    "\n",
    "* Функция для построения доверительного интервала определена в видео \"Доверительные интервалы для двух долей\" и соответствующем ноутбуке.\n",
    "* На вход ей неоходимо подавать выборки, поэтому вам необходимо сгенерировать две выборки из нулей и единиц, в которой единицы будут соответствовать людям, у которых случился инфаркт, а нули — людям, у которых за 5 лет он не произошёл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "from statsmodels.stats.weightstats import *\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "def proportions_confint_diff_ind(sum_sample1, sum_sample2, len_sample1, len_sample2, alpha = 0.05):    \n",
    "    z = scipy.stats.norm.ppf(1 - alpha / 2.)   \n",
    "    p1 = float(sum_sample1) / len_sample1\n",
    "    p2 = float(sum_sample2) / len_sample2\n",
    "    \n",
    "    left_boundary = (p1 - p2) - z * np.sqrt(p1 * (1 - p1)/ len_sample1 + p2 * (1 - p2)/ len_sample2)\n",
    "    right_boundary = (p1 - p2) + z * np.sqrt(p1 * (1 - p1)/ len_sample1 + p2 * (1 - p2)/ len_sample2)\n",
    "    \n",
    "    return (left_boundary, right_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.004687750675049439, 0.010724297276960124)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportions_confint_diff_ind(189, 104, 11034, 11037, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Отношение шансов инфаркта при приёме аспирина и плацебо\n",
    "\n",
    "Для ответа на этот вопрос не нужно даже генерировать выборки — достаточно рассчитать шансы по формуле, приведённой в условии, и поделить их друг на друга в правильном порядке.\n",
    "Проверьте, что в вашей цепочке вычислений нет промежуточных округлений (например, что вы не округляете шансы перед тем, как их делить друг на друга)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.83205394191\n"
     ]
    }
   ],
   "source": [
    "print  (p_1 / (1 - p_1)) / (p / (1 - p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Доверительный интервал для отношения шансов\n",
    "\n",
    "В этом задании есть элемент случайности, поэтому, чтобы получить такой же ответ, какой прописан в грейдере, вам нужно в точности вопроизвести последовательность действий из условия задания.\n",
    "\n",
    "* При создании исходных выборок сначала записывайте в них единицы, а потом нули.\n",
    "* Установите random_seed один раз перед началом генерации бутстреп-псевдовыборок. Помните, что установка random_seed должна делаться в той же ячейке ноутбука, что и генерация выборок.\n",
    "* Генерируйте псевдовыборки с помощью функции get_bootstrap_samples из ноутбука урока \"Доверительные интервалы на основе бутстрепа\". Чтобы сгенерировать все необходимые псевдовыборки, вам понадобится два вызова этой функции.\n",
    "* Если вы использовали в вашем решении код из ноутбука урока \"Доверительные интервалы на основе бутстрепа\", убедитесь, что в нём не осталось кусков, относящихся к задаче, решавшейся в этом ноутбуке (например, что вы не считаете на псевдовыборках разность медиан вместо отношения шансов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.44419465 2.34321168]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "def stat_intervals(stat, alpha):\n",
    "    boundaries = np.percentile(stat, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "    return boundaries\n",
    "\n",
    "p_plac = np.append(np.repeat(1.0, 104), np.repeat(0.0, 11037-104))\n",
    "\n",
    "p_true = np.append(np.repeat(1.0, 189), np.repeat(0.0, 11034-189))\n",
    "\n",
    "def shance(a,b):\n",
    "    return (a/b)/(1-a/b)\n",
    "\n",
    "def get_bootstrap_samples(data, n_samples):\n",
    "    indices = np.random.randint(0, len(data), (n_samples, len(data)))\n",
    "    samples = data[indices]\n",
    "    return samples\n",
    "\n",
    "placebo = map(lambda x:shance(sum(x),len(x)), get_bootstrap_samples(p_plac, 1000))\n",
    "aspirin = map(lambda x:shance(sum(x),len(x)), get_bootstrap_samples(p_true, 1000))\n",
    "\n",
    "vect_ot_chanse=map(lambda x: x[1]/x[0], zip(placebo, aspirin))\n",
    "\n",
    "print stat_intervals(vect_ot_chanse, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Опрос в ресторане\n",
    "\n",
    "Если у вас не получается понять, что от вас требуется, попробуйте переформулировать вопрос в терминах проверки гипотез:”отличается ли уровень стресса сотрудников ресторана от среднего?”\n",
    "\n",
    "Также обратите внимание на тот вид альтернативы, которую будете использовать - односторонняя или двусторонняя альтернатива?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9724054358699054"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.binom_test(67, 100, 0.75, alternative = 'greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sn</th>\n",
       "      <th>we</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200.0</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199.3</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>193.6</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167.7</td>\n",
       "      <td>35.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183.9</td>\n",
       "      <td>45.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sn    we\n",
       "0  200.0   8.8\n",
       "1  199.3  10.0\n",
       "2  193.6  22.4\n",
       "3  167.7  35.6\n",
       "4  183.9  45.4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset=pd.read_csv(\"pines.txt\",delimiter=\"\\t\")\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.36\n",
      "23.36\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binned_statistic_2d\n",
    "bins = [0.0, 40.0, 80.0, 120.0, 160.0, 200.0]\n",
    "result = binned_statistic_2d(dataset['sn'], dataset['we'], None, 'count', bins=[bins,bins])\n",
    "print np.mean(result.statistic)\n",
    "print len(dataset)/25.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=150.58904109589042, pvalue=nan)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = result.statistic.reshape(25)\n",
    "array_stat = [len(dataset)/25.0] * 25\n",
    "stats.chisquare(array, array_stat, ddof = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
