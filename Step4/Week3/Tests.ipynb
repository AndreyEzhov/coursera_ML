{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2412"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.6548\n",
    "-0.6317\n",
    "-0.3686\n",
    "-0.1090\n",
    "5\n",
    "0.0539\n",
    "6\n",
    "293.6831\n",
    "62\n",
    "0.2412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>town</th>\n",
       "      <th>mortality</th>\n",
       "      <th>hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South</td>\n",
       "      <td>Bath</td>\n",
       "      <td>1247</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North</td>\n",
       "      <td>Birkenhead</td>\n",
       "      <td>1668</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>1466</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>North</td>\n",
       "      <td>Blackburn</td>\n",
       "      <td>1800</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>North</td>\n",
       "      <td>Blackpool</td>\n",
       "      <td>1609</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location        town  mortality  hardness\n",
       "0    South        Bath       1247       105\n",
       "1    North  Birkenhead       1668        17\n",
       "2    South  Birmingham       1466         5\n",
       "3    North   Blackburn       1800        14\n",
       "4    North   Blackpool       1609        18"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water = pd.read_csv('water.txt', sep = '\\t')\n",
    "water.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mortality = water.mortality.values\n",
    "hardness = water.hardness.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6548486232042464\n"
     ]
    }
   ],
   "source": [
    "sum_1 = 0\n",
    "sum_2 = 0\n",
    "sum_3 = 0\n",
    "\n",
    "for mort, hard in zip(mortality, hardness):\n",
    "    sum_1 += (mort - np.mean(mortality)) * (hard - np.mean(hardness))\n",
    "    sum_2 += (mort - np.mean(mortality)) ** 2\n",
    "    sum_3 += (hard - np.mean(hardness)) ** 2\n",
    "    \n",
    "print sum_1 / (sum_2 * sum_3) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.6548486232042465, 1.0331339260349571e-08)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr(mortality, hardness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=-0.6316646189166502, pvalue=4.79546153722838e-08)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "spearmanr(mortality, hardness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.6021532715484158, 0.0011346743048161927)\n",
      "(-0.3685978383288718, 0.029344659047110606)\n"
     ]
    }
   ],
   "source": [
    "south = water[water.location == 'South']\n",
    "south_pear = pearsonr(south.mortality.values, south.hardness.values)\n",
    "\n",
    "north = water[water.location == 'North']\n",
    "north_pear = pearsonr(north.mortality.values, north.hardness.values)\n",
    "\n",
    "print south_pear\n",
    "print north_pear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.109002374587\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "a = 203\n",
    "b = 718\n",
    "c = 239\n",
    "d = 515\n",
    "print (a * d - b * c) / ((a + b) * (a + c) * (b + d) * (d + c)) ** 0.5\n",
    "from sklearn.metrics import matthews_corrcoef \n",
    "print matthews_corrcoef([a, c], [b, d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19.40753078854304,\n",
       " 1.0558987006638725e-05,\n",
       " 1,\n",
       " array([[243.03402985, 677.96597015],\n",
       "        [198.96597015, 555.03402985]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "chi2_contingency([[a, b], [c, d]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9271792226870357, 0.16506738276246485, 1, array([[53.00970874, 24.99029126],\n",
       "        [86.99029126, 41.00970874]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_contingency([[48, 30], [92, 36]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293.68311039689746,\n",
       " 2.4964299580093467e-62,\n",
       " 4,\n",
       " array([[ 93.08597464, 153.74722662,  94.16679873],\n",
       "        [381.6251981 , 630.318542  , 386.0562599 ],\n",
       "        [214.28882726, 353.93423138, 216.77694136]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_contingency([[197, 111, 33], [382, 685, 331], [110, 342, 333]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "def cramers_corrected_stat(confusion_matrix):\n",
    "    \"\"\" calculate Cramers V statistic for categorial-categorial association.\n",
    "        uses correction from Bergsma and Wicher, \n",
    "        Journal of the Korean Statistical Society 42 (2013): 323-328\n",
    "    \"\"\"\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum()\n",
    "    phi2 = chi2/n\n",
    "    r,k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))    \n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min( (kcorr-1), (rcorr-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2412013934500338"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cramers_corrected_stat(np.array([[197, 111, 33], [382, 685, 331], [110, 342, 333]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "fem = np.append(np.ones(203), np.zeros(718))\n",
    "mal = np.append(np.ones(239), np.zeros(515))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_diff_confint_ind(sample1, sample2, alpha = 0.05):    \n",
    "    z = scipy.stats.norm.ppf(1 - alpha / 2.)\n",
    "    \n",
    "    p1 = float(sum(sample1)) / len(sample1)\n",
    "    p2 = float(sum(sample2)) / len(sample2)\n",
    "    \n",
    "    left_boundary = (p1 - p2) - z * np.sqrt(p1 * (1 - p1)/ len(sample1) + p2 * (1 - p2)/ len(sample2))\n",
    "    right_boundary = (p1 - p2) + z * np.sqrt(p1 * (1 - p1)/ len(sample1) + p2 * (1 - p2)/ len(sample2))\n",
    "    \n",
    "    return (left_boundary, right_boundary)\n",
    "\n",
    "def proportions_diff_z_stat_ind(sample1, sample2):\n",
    "    n1 = len(sample1)\n",
    "    n2 = len(sample2)\n",
    "    \n",
    "    p1 = float(sum(sample1)) / n1\n",
    "    p2 = float(sum(sample2)) / n2 \n",
    "    P = float(p1*n1 + p2*n2) / (n1 + n2)\n",
    "    \n",
    "    return (p1 - p2) / np.sqrt(P * (1 - P) * (1. / n1 + 1. / n2))\n",
    "\n",
    "def proportions_diff_z_test(z_stat, alternative = 'two-sided'):\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return 2 * (1 - scipy.stats.norm.cdf(np.abs(z_stat)))\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return scipy.stats.norm.cdf(z_stat)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return 1 - scipy.stats.norm.cdf(z_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.053905233215813156, 0.13922183141523897)\n"
     ]
    }
   ],
   "source": [
    "print proportions_diff_confint_ind(mal, fem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.153453089576601e-06"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportions_diff_z_test(proportions_diff_z_stat_ind(mal, fem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберите задачи, в которых обязательно нужно применять поправку на множественную проверку гипотез\n",
    "\n",
    "* Сравнение эффективности лечения пациентов в подгруппах по большому количеству признаков\n",
    "\n",
    "* Выбор инвестиционных фондов с помощью сравнения доходности каждого из них с доходностью базового актива по нескольким историческим периодам\n",
    "\n",
    "* Попарное сравнение средних большого количества выборок\n",
    "\n",
    "* Локализация различий в активности мозга испытуемых в разных экспериментальных условиях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификатор C4.5 и три его модификации: с оптимизацией гиперпараметра m, гиперпараметра cf и с одновременной оптимизацией обоих гиперпараметров. Эти четыре классификатора сравнивались на 14 наборах данных. На каждом датасете был посчитан AUC каждого классификатора. Данные записаны в файле:\n",
    "        Используя критерий знаковых рангов, проведите попарное сравнение каждого классификатора с каждым. Выберите два классификатора, различие между которыми наиболее статистически значимо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>C4.5</th>\n",
       "      <th>C4.5+m</th>\n",
       "      <th>C4.5+cf</th>\n",
       "      <th>C4.5+m+cf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult (sample)</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breast cancer</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>breast cancer wisconsin</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cmc</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ionosphere</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Unnamed: 0   C4.5  C4.5+m  C4.5+cf  C4.5+m+cf\n",
       "0           adult (sample)  0.763   0.768    0.771      0.798\n",
       "1            breast cancer  0.599   0.591    0.590      0.569\n",
       "2  breast cancer wisconsin  0.954   0.971    0.968      0.967\n",
       "3                      cmc  0.628   0.661    0.654      0.657\n",
       "4               ionosphere  0.882   0.888    0.886      0.898"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs = pd.read_csv('AUCs.txt', sep = '\\t')\n",
    "aucs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WilcoxonResult(statistic=6.5, pvalue=0.01075713311978963) ('C4.5', 'C4.5+m')\n",
      "WilcoxonResult(statistic=43.0, pvalue=0.861262330095348) ('C4.5', 'C4.5+cf')\n",
      "WilcoxonResult(statistic=11.0, pvalue=0.015906444101703374) ('C4.5', 'C4.5+m+cf')\n",
      "WilcoxonResult(statistic=17.0, pvalue=0.046332729793395394) ('C4.5+m', 'C4.5+cf')\n",
      "WilcoxonResult(statistic=22.0, pvalue=0.3278256758446406) ('C4.5+m', 'C4.5+m+cf')\n",
      "WilcoxonResult(statistic=10.0, pvalue=0.022909099354356588) ('C4.5+cf', 'C4.5+m+cf')\n",
      "('C4.5', 'C4.5+m')\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "from itertools import combinations\n",
    "result = 10000000\n",
    "answer = ''\n",
    "\n",
    "counter = 0\n",
    "p = []\n",
    "for comb in combinations(['C4.5', 'C4.5+m', 'C4.5+cf', 'C4.5+m+cf'], 2):\n",
    "    cur_result = wilcoxon(- aucs[comb[0]] + aucs[comb[1]])\n",
    "    print cur_result, comb\n",
    "    if cur_result.statistic < result:\n",
    "        result = cur_result.statistic\n",
    "        answer = comb\n",
    "    if cur_result.pvalue < 0.05:\n",
    "        counter += 1\n",
    "    p.append(cur_result.pvalue)\n",
    "print answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько статистически значимых на уровне 0.05 различий мы обнаружили?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по данным из предыдущего опроса, настройка какого из параметров классификатора даёт более значимое увеличение качества?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнивая 4 классификатора между собой, мы проверили 6 гипотез. Давайте сделаем поправку на множественную проверку. Начнём с метода Холма. Сколько гипотез можно отвергнуть на уровне значимости 0.05 после поправки этим методом?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.sandbox.stats.multicomp import multipletests \n",
    "reject, p_corrected, a1, a2 = multipletests(p, \n",
    "                                            alpha = 0.05, \n",
    "                                            method = 'holm') \n",
    "print reject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько гипотез можно отвергнуть на уровне значимости 0.05 после поправки методом Бенджамини-Хохберга?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False  True False False  True]\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.sandbox.stats.multicomp import multipletests \n",
    "reject, p_corrected, a1, a2 = multipletests(p, \n",
    "                                            alpha = 0.05, \n",
    "                                            method = 'fdr_bh') \n",
    "print reject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Насколько корректно, на ваш взгляд, применение метода Бенджамини-Хохберга в этой задаче?\n",
    "\n",
    "Всегда корректно, это же метод Бенджамини-Хохберга\n",
    "\n",
    "* Некорректно: статистики, соответствующие разным гипотезам, зависимы, так что предположения метода Бенджамини-Хохберга не выполняются\n",
    "\n",
    "Корректно: статистики, соответствующие разным гипотезам, независимы, так что предположения метода Бенджамини-Хохберга выполняются"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы подозреваем, что в проведённом с C4.5 эксперименте на самом деле классификаторы сильнее отличаются друг от друга, просто нам не удалось это заметить. Что можно сделать, чтобы увеличить вероятность обнаружения различий, если они действительно существуют?\n",
    "\n",
    "* Взять больше датасетов\n",
    "\n",
    "Закрыть глаза на эффект множественной проверки гипотез и не делать никакой поправки\n",
    "\n",
    "Попробовать настроить больше гиперпараметро"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
